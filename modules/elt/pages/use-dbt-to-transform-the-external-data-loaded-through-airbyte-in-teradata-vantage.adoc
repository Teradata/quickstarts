= Use dbt to transform the external data loaded through Airbyte in Teradata Vantage
:experimental:
:page-author: Krutik Pathak
:page-email: krutik.pathak@teradata.com
:page-revdate: TBD
:description: Use dbt to transform external data loaded through Airbyte in Teradata Vantage.
:keywords: dbt, airbyte, data transformation, data warehouses, compute storage separation, teradata, vantage, cloud data platform, object storage, data transfer, data extraction, enterprise analytics, elt.
:tabs:
:dir: getting-started-with-airbyte-dbt


== Overview

This tutorial demonstrates how to use link:https://docs.getdbt.com/docs/introduction[dbt (Data Build Tool),window="_blank"] to transform external data load through link:https://github.com/airbytehq/airbyte[Airbyte,  window="_blank"] (an Open-Source Extract Load tool) in Teradata Vantage. This tutorial is based on the original link:https://github.com/dbt-labs/jaffle_shop-dev[dbt Jaffle Shop tutorial, window="_blank"] with a small change, instead of using `dbt seed`, the Jaffle Shop dataset is loaded from Google Sheets into Teradata Vantage using Airbyte. The data thus loaded into Teradata Vantage is in JSON format as can be seen in the picture below:

image::{dir}/raw_data_vantage_dbeaver.png[Raw data in Teradata Vantage, width=75%]

== Prerequisites

* Access to a Teradata Vantage Instance.
+
include::ROOT:partial$vantage_clearscape_analytics.adoc[]

* The external data link:https://docs.google.com/spreadsheets/d/1-R4F3q8J9KDnFRWpiT3Ysp1RlOoUu3PeQR7xDeLxFts/edit#gid=42273685[Jaffle Shop Dataset, window="_blank"] is loaded from Google Sheets into Teradata Vantage using Airbyte.  Please refer to link:https://quickstarts.teradata.com/elt/use-airbyte-to-load-data-from-external-sources-to-teradata-vantage.html[Use Airbyte to load data from external sources to Teradata Vantage, window="_blank"] for more details. 

[NOTE]
====
When you configure a Teradata destination in Airbyte, it will ask for a `Default Schema`. For this demonstration we have set the `Default Schema` as `airbyte_jaffle_shop`. 
====

* Python 3.7, 3.8, 3.9, 3.10 or 3.11 installed.

== Install dbt
* Create a new python environment to manage dbt and its dependencies. Activate the environment:
+
[source, bash]
----
python3 -m venv env
source env/bin/activate
----

+
[NOTE]
====
You can activate the virtual environment in Windows using `git bash` with command `source myenv/Scripts/activate`.
====

* Install `dbt-teradata` module and its dependencies. The core dbt module is included as a dependency so you don't have to install it separately:
+
[source, bash]
----
pip install dbt-teradata
----

== Configure dbt
* Initialize a dbt project.
+
[source, bash]
----
dbt init
----

It will ask you for the project name and database management system. In this demo we define the project name as `dbt_airbyte_demo`. Since we are using the dbt-teradata connector, the only database management system available is Teradata.

image::{dir}/dbt_init_project_name.png[Project name prompt, width=75%]

image::{dir}/dbt_init_database_name.png[Database name prompt, width=75%]
 
* Configure `profiles.yml` file located in the `$HOME/.dbt` directory. If the `profiles.yml` file is not present, you can create a new one. 
Adjust `server`, `username`, `password` to match your Teradata instance's `HOST`, `Username`, `Password` respectively. 
Here `schema` is the database that contains the Airbyte raw Jaffle Shop dataset in JSON format. In this use case we have used the `schema` as `airbyte_jaffle_shop`.

[source, yaml, id="dbt_first_config", role="emits-gtm-events"]
----
dbt_airbyte_demo:
  target: dev
  outputs:
    dev:
      type: teradata
      server: <host>
      schema: airbyte_jaffle_shop
      username: <user>
      password: <password>
      tmode: ANSI

----

* Once the `profiles.yml` file is ready, we can validate the setup. Go to the dbt project folder and run the command:

[source, bash]
----
dbt debug
----
If the debug command returned errors, you likely have an issue with the content of `profiles.yml`. If the setup is correct, you will get message `All checks passed!`

image::{dir}/dbt_debug.png[dbt debug output, width=75%]

== About the Jaffle Shop warehouse

`jaffle_shop` is a fictional e-commerce store. It consists of `customers`, `orders` and `payments` tables with the following entity relationship diagram:

[erd, format=svg, width=100%]
....
# Entities

[customers] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  `first_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `last_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `email  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}

[orders] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`user_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `order_date  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `status  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}

[payments] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`order_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `payment_method  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

# Relationships

customers   1--* orders
orders      1--* payments
....

The data in the source system is normalized. The following is the dimensional model of same data which is more suitable for analytics tools:
[erd, format=svg, width=100%]
....
# Entities

[`dimension: customers`] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`customer_id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  `first_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `last_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `email  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `first_order  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `most_recent_order  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `number_of_orders  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `total_order_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

[`fact: orders`] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`order_id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`customer_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `order_date  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `status  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `credit_card_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `coupon_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `bank_transfer_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `gift_card_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

# Relationships
`dimension: customers`   1--* `fact: orders`
....

== Understanding Transformations
This dbt project performs two fold transformation. 

* First, it transforms the raw data which is in JSON format loaded in Teradata Vantage with Airbyte from Google Sheets into staging views (staging models) that are normalized. 
* Next, it transforms the normalized views into a dimensional model with customer and order data ready for analytics.

The following diagram shows the transformation steps in Teradata Vantage using dbt:
[ditaa]
----
    /--------------\   JSON Transformation  /------------------\
    | Raw JSON Data|----------------------->| Normalized Views |
    \--------------/                        \------------------/
                                                      |
                                                      | Dimensional Modeling
                                                      v
                                               /-------------\
                                               |  Dimension  |  
                                               |    and      |
                                               | Fact Tables |
                                               \-------------/     
----

In the original link:https://github.com/dbt-labs/jaffle_shop-dev[dbt Jaffle Shop tutorial, window="_blank"] we get the data from raw csv files in the `./data` into staging views in `./models/staging` using `dbt seed`. Here, in our example we transform the raw JSON data in Teradata Vantage into Normalized views in these staging models. `stg_customers` model creates the normalized view for `customers` from `_airbyte_raw_customers` table. Similarly `stg_orders` model creates for normalized view for `orders` from `_airbyte_raw_orders` and `stg_payments` model creates normalized view for `payments` from `_airbyte_raw_payments`. 

The given below is an example of JSON transformation in `stg_orders.sql` model: 
[source, sql]
----
WITH flattened_json_data AS (
  SELECT
    _airbyte_data.JSONExtractValue('$.id') AS order_id,
    _airbyte_data.JSONExtractValue('$.user_id') AS customer_id,
    _airbyte_data.JSONExtractValue('$.order_date') AS order_date,
    _airbyte_data.JSONExtractValue('$.status') AS status
  FROM airbyte_jaffle_shop._airbyte_raw_orders
)


SELECT * FROM flattened_json_data
----

=== Dimensional Modeling
Dimension Modeling is a two step process: 

* First, dbt takes the normalized views in `stg_orders`, `stg_customers`, `stg_payments` and builds denormalized intermediate join tables `customer_orders`, `order_payments`, `customer_payments`. You will find the definitions of these tables in `./models/marts/core/intermediate`.  
* In the second step, dbt creates `dim_customers` and `fct_orders` tables. These are the dimensional model tables that we want to expose to our BI tool. You will find the definitions of these tables in `./models/marts/core`.

The code for intermediate and final dimension models is already available in the original link:https://github.com/dbt-labs/jaffle_shop-dev[dbt Jaffle Shop tutorial, window="_blank"].

==== Create Dimesional Models
Now we create the models using the command:

[source, bash]
----
dbt run
----
You will get the status of each model as given below:

image::{dir}/dbt_run.png[dbt run output, width=75%]

=== Test the data
dbt applied multiple transformations to our data. To ensure that the data in the dimensional model is correct, dbt allows us to define and execute tests against the data. The tests are defined in `./models/marts/core/schema.yml` and `./models/staging/schema.yml`. The files describe each column in all relationships. Each column can have multiple tests configured under `tests` key. For example, we expect that `fct_orders.order_id` column will contain unique, non-null values. To validate that the data in the produced tables satisfies the test conditions run:

[source, bash]
----
dbt test
----

If the data in the models satisfies all the test cases, then you will get results as given below:

image::{dir}/dbt_test.png[dbt test output, width=75%]

=== Generate documentation

Our model consists of just a few tables. Imagine a scenario where where we have many more sources of data and a much more complex dimensional model. We could also have an intermediate zone between the raw data and the dimensional model that follows the Data Vault 2.0 principles. Would it not be useful, if we had the inputs, transformations and outputs documented somehow? dbt allows us to generate documentation from its configuration files:

[source, bash]
----
dbt docs generate
----

This will produce html files in `./target` directory.

You can start your own server to browse the documentation. The following command will start a server and open up a browser tab with the docs' landing page:

[source, bash]
----
dbt docs serve
----

==== Lineage Graph

image::{dir}/dbt_docs_serve.png[dbt lineage graph, width=75%]

== Summary

This tutorial demonstrated how to use dbt to transform the raw JSON data loaded through Airbyte into dimensional model in Teradata Vantage. The sample project takes raw JSON data loaded in Teradata Vantage, creates normalized views and finally produces a dimensional data mart. We used dbt to transform JSON into Normalized views and multiple dbt commands to create models (`dbt run`), test the data (`dbt test`), and generate and serve model documentation (`dbt docs generate`, `dbt docs serve`).


== Further reading
* link:https://docs.getdbt.com/docs/[dbt documentation]
* link:https://github.com/Teradata/dbt-teradata[dbt-teradata plugin documentation]

include::ROOT:partial$community_link.adoc[]
