= Configure a Teradata Vantage connection in DataHub
:experimental:
:page-author: Paul Ibberson
:page-email: paul.ibberson2@teradata.com
:page-revdate: Deccember 19th, 2023
:page-image-directory: configure-a-teradata-connection-in-datahub
:description: Configure a Teradata Vantage connection in DataHub.
:keywords: data warehouses, compute storage separation, teradata, vantage, cloud data platform, object storage, business intelligence, enterprise analytics, datahub, data catalog, data lineage


== Overview

This how-to demonstrates how to create a connection to Teradata Vantage with DataHub, and ingest metadata about tables and views, along with usage and lineage information.

== Prerequisites

* Access to a Teradata Vantage instance.
+
include::ROOT:partial$vantage_clearscape_analytics.adoc[]

* DataHub installed. See link:https://datahubproject.io/docs/quickstart/[DataHub Quickstart Guide]

== Setup DataHub

* Install the Teradata plugin for DataHub in the environment where you have DataHub installed
+
[source, bash]
----
pip install 'acryl-datahub[teradata]'
----

* Setup a Teradata user and set privileges to allow that user to read the dictionary tables
+
[source, sql ]
----
CREATE USER datahub FROM <database> AS PASSWORD = <password> PERM = 20000000;

GRANT SELECT ON dbc.columns TO datahub;
GRANT SELECT ON dbc.databases TO datahub;
GRANT SELECT ON dbc.tables TO datahub;
GRANT SELECT ON DBC.All_RI_ChildrenV TO datahub;
GRANT SELECT ON DBC.ColumnsV TO datahub;
GRANT SELECT ON DBC.IndicesV TO datahub;
GRANT SELECT ON dbc.TableTextV TO datahub;
GRANT SELECT ON dbc.TablesV TO datahub;
GRANT SELECT ON dbc.dbqlogtbl TO datahub; -- if lineage or usage extraction is enabled
----
* If you want to run profiling, you need to grant select permission on all the tables you want to profile.

* If you want to extract lineage or usage metadata, query logging must be enabled and it is set to size which will fit for your queries (the default query text size Teradata captures is max 200 chars) An example how you can set it for all users:
+
[source, sql ]
----
-- set up query logging on all

REPLACE QUERY LOGGING LIMIT SQLTEXT=2000 ON ALL;
----

== Add a Teradata connection to DataHub
With DataHub running, open the DataHub GUI and login.  In this example this is running at localhost:9002 

. Start the new connection wizard by clicking on the ingestion plug icon 
+
image::{page-image-directory}/ingestion-icon.png[Ingestion Label, width=75%]
+
and then selecting "Create new source" 
+
image::{page-image-directory}/create-new-source.png[Create New Source, width=50%]

. Scroll the list of available sources and select Other 
+
image::{page-image-directory}/select-other-source.png[Select Source, width=50%]

. A recipe is needed to configure the connection to Teradata and define the options required such as whether to capture table and column lineage, profile the data or retrieve usage statistics.  Below is a simple recipe to get you started. The host, username and password should be changed to match your environment.
+
[source, yaml]
----
pipeline_name: my-teradata-ingestion-pipeline
source:
  type: teradata
  config:
    host_port: "myteradatainstance.teradata.com:1025"
    username: myuser
    password: mypassword
    #database_pattern:
    #  allow:
    #    - "my_database"
    #  ignoreCase: true
    include_table_lineage: true
    include_usage_statistics: true
    stateful_ingestion:
      enabled: true
----
+
Pasting the recipe into the window should look like this: 
+
image::{page-image-directory}/new-ingestion-source.png[New Ingestion Source, width=75%]

. Click Next and then setup the required schedule. 
+
image::{page-image-directory}/set-schedule.png[Set Schedule, width=75%]

. Click Next to Finish Up and give the connection a name. Click Advanced so that the correct CLI version can be set. DataHub support for Teradata became available in CLI 0.12.x.  Suggest selecting the most current version to ensure the best compatibility.
+
image::{page-image-directory}/finish-up.png[Finish up, width=75%]

. Once the new source has been saved, it can be executed manually by clicking Run. 
+
image::{page-image-directory}/execute.png[Execute, width=75%]
+
Clicking on "Succeeded" after a sucessful execution will bring up a dialogue similar to this one where you can see the Databases, Tables and Views that have been ingested into DataHub.  
+
image::{page-image-directory}/ingestion-result.png[Ingestion Result, width=75%]

. The metadata can now be explored in the GUI by browsing:
.. DataSets provides a list of the datasets (tables and views) loaded
+
image::{page-image-directory}/datasets.png[datasets, width=75%]
.. Entities captured from the database
+
image::{page-image-directory}/entities-list.png[Entities, width=75%]
.. Schema of an entity showing column/field names, data types and usage if it has been captured
+
image::{page-image-directory}/schema.png[Schema display, width=75%]
.. Lineage providing a visual representation of how data is linked between tables and views
+
image::{page-image-directory}/lineage-weather.png[Lineage picture, width=75%]

== Summary

This how-to demonstrated how to create a connection to Teradata Vantage with DataHub in order to capture metadata of tables, views along with lineage and usage statistics.

== Further reading
* https://datahubproject.io/docs/generated/ingestion/sources/teradata[Integrate DataHub with Teradata Vantage]
* https://datahubproject.io/docs/metadata-ingestion/#recipes[DataHub Integration Options for Recipes]

include::ROOT:partial$community_link.adoc[]
