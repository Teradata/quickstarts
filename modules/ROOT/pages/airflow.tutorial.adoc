=  Airflow Installation
:experimental:
:page-author: Igor Machin, Ambrose Inman
:page-email: igor.machin@teradata.com, ambrose.inman@teradata.com
:page-revdate: July 20, 2022
:description: Install airflow on EC2
:keywords: airflow, queries
:tabs:

== Overview

This tutorial demonstrates how to install airflow on an EC2

== Prerequsites

* Access to a AWS.
* Python 3.7, 3.8 or 3.9 installed.

== Create EC2

1. In AWS create a EC2 - Red hat 8 CPU, 32 GB Memory, 60 GB storage space. Remember to open the port for traffic coming from your computer.

2. In the EC2, create the airflow files.
+
[source, bash]
----
mkdir airflow
cd airflow
mkdir -p ./dags ./logs ./plugins ./data ./config ./data
echo -e "AIRFLOW_UID=$(id -u)" > .env
----
3. Install `dbt-teradata` module and its dependencies. The core dbt module is included as a dependency so you don't have to install it separately:
+
[source, bash]
----
pip install dbt-teradata
----

== Install Docker

We will now install docker onto our instance. Make sure you are in the airflow directory.

1. If you have an RHEL linux system, podman may be installed. Before docker can be dowloaded, podman must be uninstalled.
+
[source, bash]
----
sudo yum remove docker \
docker-client \
docker-client-latest \
docker-common \
docker-latest \
docker-latest-logrotate \
docker-logrotate \
docker-engine \
podman \
runc
----

2. Now that podman is uninstalled, we can install docker. Install yum utilities
+
[source, bash]
----
sudo yum install -y yum-utils
----

3. Add docker to yum repository.
+
[source, bash]
----
sudo yum-config-manager \
--add-repo \
https://download.docker.com/linux/centos/docker-ce.repo
----

4. Install docker.
+
[source, bash]
----
sudo yum install docker-ce docker-ce-cli containerd.io
----

5. Start docker as a service.
+
This sets the system up so that docker will automatically run when the system starts up.

[source, bash]
----
sudo systemctl enable docker
----
This starts docker now.
[source, bash]
----
sudo systemctl start docker
----
Install docker.

[source, bash]
----
sudo yum install docker-ce docker-ce-cli containerd.io
----

If the debug command returned errors, you likely have an issue with the content of `profiles.yml`.

== About the Jaffle Shop warehouse

`jaffle_shop` is a fictional e-commerce store. This dbt project transforms raw data from an app database into a dimensional model with customer and order data ready for analytics.

The raw data from the app consists of customers, orders, and payments, with the following entity-relationship diagram:

[erd, format=svg, width=100%]
....
# Entities

[customers] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  `first_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `last_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `email  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}

[orders] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`user_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `order_date  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `status  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}

[payments] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`order_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `payment_method  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

# Relationships

customers   1--* orders
orders      1--* payments
....

dbt takes these raw data table and builds the following dimensional model, which is more suitable for analytics tools:
[erd, format=svg, width=100%]
....
# Entities

[`dimension: customers`] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`customer_id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  `first_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `last_name  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `email  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `first_order  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `most_recent_order  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `number_of_orders  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `total_order_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

[`fact: orders`] {bgcolor: "#f37843", color: "#ffffff", border: "0", border-color: "#ffffff"}
  *`order_id  ` {bgcolor: "#f9d6cd", color: "#000000", label: "int", border: "1", border-color: "#ffffff"}
  +`customer_id  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `order_date  ` {bgcolor: "#fcece8", color: "#868686", label: "date", border: "1", border-color: "#ffffff"}
  `status  ` {bgcolor: "#fcece8", color: "#868686", label: "varchar", border: "1", border-color: "#ffffff"}
  `amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `credit_card_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `coupon_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `bank_transfer_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}
  `gift_card_amount  ` {bgcolor: "#fcece8", color: "#868686", label: "int", border: "1", border-color: "#ffffff"}

# Relationships
`dimension: customers`   1--* `fact: orders`
....

== Run dbt

=== Create raw data tables

In real life, we will be getting raw data from platforms like Segment, Stitch, Fivetran or another ETL tool. In our case, we will use dbt's `seed` functionality to create tables from csv files. The csv files are located in `./data` directory. Each csv file will produce one table. dbt will inspect the files and do type inference to decide what data types to use for columns.

Let's create the raw data tables:
[source, bash]
----
dbt seed
----

You should now see 3 tables in your `jaffle_shop` database: `raw_customers`, `raw_orders`, `raw_payments`. The tables should be populated with data from the csv files.

=== Create the dimensional model

Now that we have the raw tables, we can instruct dbt to create the dimensional model:
[source, bash]
----
dbt run
----

So what exactly happened here? dbt created additional tables using `CREATE TABLE/VIEW FROM SELECT` SQL. In the first transformation, dbt took raw tables and built denormalized join tables called `customer_orders`, `order_payments`, `customer_payments`. You will find the definitions of these tables in `./marts/core/intermediate`.
In the second step, dbt created `dim_customers` and `fct_orders` tables. These are the dimensional model tables that we want to expose to our BI tool.

=== Test the data

dbt applied multiple transformations to our data. How can we ensure that the data in the dimensional model is correct? dbt allows us to define and execute tests against the data. The tests are defined in `./marts/core/schema.yml`. The file describes each column in all relationships. Each column can have multiple tests configured under `tests` key. For example, we expect that `fct_orders.order_id` column will contain unique, non-null values. To validate that the data in the produced tables satisfies the test conditions run:

[source, bash]
----
dbt test
----

=== Generate documentation

Our model consists of just a few tables. Imagine a scenario where where we have many more sources of data and a much more complex dimensional model. We could also have an intermediate zone between the raw data and the dimensional model that follows the Data Vault 2.0 principles. Would it not be useful, if we had the inputs, transformations and outputs documented somehow? dbt allows us to generate documentation from its configuration files:

[source, bash]
----
dbt docs generate
----

This will produce html files in `./target` directory.

You can start your own server to browse the documentation. The following command will start a server and open up a browser tab with the docs' landing page:

[source, bash]
----
dbt docs serve
----

== Summary

This tutorial demonstrated how to use dbt with Teradata Vantage. The sample project takes raw data and produces a dimensional data mart. We used multiple dbt commands to populate tables from csv files (`dbt seed`), create models (`dbt run`), test the data (`dbt test`), and generate and serve model documentation (`dbt docs generate`, `dbt docs serve`).

== Further reading
* link:https://docs.getdbt.com/docs/[dbt documentation]
* link:https://github.com/Teradata/dbt-teradata[dbt-teradat
